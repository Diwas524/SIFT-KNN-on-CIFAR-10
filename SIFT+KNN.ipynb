{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcJK3kXl--c3"
   },
   "source": [
    "# EECS 498-007/598-005 Assignment 1-1: KNN SIFT\n",
    "\n",
    "Before we start, please put your name and UMID in following format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sA2iBcm_cPb"
   },
   "source": [
    "**Your Answer:**   \n",
    "Diwas Pandey, #011805103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRW8qLB-7z3I"
   },
   "source": [
    "#KNN with SIFT feature\n",
    "\n",
    "The provided code loads the CIFAR-10 dataset, applies SIFT feature extraction to images, constructs a codebook using MiniBatchKMeans clustering, computes Bag of Visual Words (BoVW) representations, trains a K-Nearest Neighbors (K-NN) classifier, and evaluates scene recognition accuracy. It starts by preprocessing and loading the CIFAR-10 dataset. Then, it extracts SIFT features from the images, creates a codebook for clustering these features, and computes BoVW representations for both training and testing data. A K-NN classifier is trained on the training data, and its accuracy is evaluated on the test data, with results including accuracy and a classification report. Hyperparameters like the number of clusters, batch size, and the number of neighbors can be adjusted to optimize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBsKX3fC2enp",
    "outputId": "09278536-0298-46a0-c6b6-3693de28380d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10374524334067695\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.26      0.15       998\n",
      "           1       0.10      0.17      0.13       999\n",
      "           2       0.11      0.12      0.12       999\n",
      "           3       0.08      0.07      0.08       997\n",
      "           4       0.08      0.06      0.07      1000\n",
      "           5       0.11      0.08      0.09       998\n",
      "           6       0.14      0.08      0.10      1000\n",
      "           7       0.11      0.07      0.09       998\n",
      "           8       0.09      0.05      0.07       997\n",
      "           9       0.11      0.07      0.08      1000\n",
      "\n",
      "    accuracy                           0.10      9986\n",
      "   macro avg       0.10      0.10      0.10      9986\n",
      "weighted avg       0.10      0.10      0.10      9986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "def load_cifar10():\n",
    "    # Step 1: Load CIFAR-10 dataset and preprocess it\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    # Download CIFAR-10 dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "    # Extract labels from the dataset\n",
    "    train_labels = np.array(trainset.targets)\n",
    "    test_labels = np.array(testset.targets)\n",
    "\n",
    "    return train_labels, test_labels, trainset, testset\n",
    "\n",
    "def extract_sift_features(images):\n",
    "    # Step 2: Extract SIFT features from CIFAR-10 images using OpenCV's SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    sift_features = []\n",
    "\n",
    "    for image in images:\n",
    "        gray_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
    "        kp, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "        if descriptors is not None:\n",
    "            sift_features.append(descriptors)\n",
    "\n",
    "    return sift_features\n",
    "\n",
    "def create_codebook(features, num_clusters, batch_size):\n",
    "    # Step 3: Create a codebook using MiniBatchKMeans clustering\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, batch_size=batch_size, random_state=0)\n",
    "    kmeans.fit(features)\n",
    "    return kmeans\n",
    "\n",
    "def compute_bovw_representation(features, codebook):\n",
    "    # Step 4: Compute Bag of Visual Words (BoVW) representations for train and test data\n",
    "    num_clusters = codebook.n_clusters\n",
    "    bovw_representation = []\n",
    "\n",
    "    for image_features in features:\n",
    "        if len(image_features) > 0:\n",
    "            # Assign each feature to a cluster\n",
    "            cluster_assignments = codebook.predict(image_features)\n",
    "\n",
    "            # Create a histogram of cluster frequencies\n",
    "            histogram = np.bincount(cluster_assignments, minlength=num_clusters)\n",
    "\n",
    "            # Normalize the histogram\n",
    "            histogram = histogram / np.sum(histogram)\n",
    "\n",
    "            bovw_representation.append(histogram)\n",
    "        else:\n",
    "            # Handle cases where no features were detected\n",
    "            bovw_representation.append(np.zeros(num_clusters))\n",
    "\n",
    "    return bovw_representation\n",
    "\n",
    "def train_knn_classifier(train_bovw_features, train_labels):\n",
    "    # Step 5: Create and train a Nearest Neighbors classifier (BallTree)\n",
    "    knn_classifier = NearestNeighbors(n_neighbors=5, algorithm='ball_tree', n_jobs=-1)\n",
    "\n",
    "    # Fit the classifier on the training data\n",
    "    knn_classifier.fit(train_bovw_features)\n",
    "\n",
    "    return knn_classifier\n",
    "\n",
    "def evaluate_classifier(classifier, test_bovw_features, train_labels):\n",
    "    # Step 6: Find nearest neighbors for test data\n",
    "    distances, indices = classifier.kneighbors(test_bovw_features)\n",
    "\n",
    "    # Step 7: Evaluate the classifier\n",
    "    # Calculate the most common class label among neighbors\n",
    "    predictions = []\n",
    "\n",
    "    for neighbors in indices:\n",
    "        if len(neighbors) > 0:\n",
    "            neighbor_labels = train_labels[neighbors]\n",
    "            most_common_label = np.bincount(neighbor_labels).argmax()\n",
    "            predictions.append(most_common_label)\n",
    "        else:\n",
    "            # Handle cases where no neighbors were found\n",
    "            predictions.append(-1)  # You can choose an appropriate value\n",
    "\n",
    "    # Filter out test samples without predictions (-1)\n",
    "    filtered_test_labels = []\n",
    "    filtered_predictions = []\n",
    "\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction != -1:\n",
    "            filtered_test_labels.append(test_labels[i])\n",
    "            filtered_predictions.append(prediction)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(filtered_test_labels, filtered_predictions)\n",
    "    report = classification_report(filtered_test_labels, filtered_predictions)\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "def main():\n",
    "    train_labels, test_labels, trainset, testset = load_cifar10()\n",
    "    train_sift_features = extract_sift_features(trainset.data)\n",
    "    test_sift_features = extract_sift_features(testset.data)\n",
    "\n",
    "    num_clusters = 100  # You can adjust the number of clusters\n",
    "    batch_size = 1000   # You can adjust the batch size\n",
    "\n",
    "    concatenated_train_sift_features = np.vstack(train_sift_features)\n",
    "    codebook = create_codebook(concatenated_train_sift_features, num_clusters, batch_size)\n",
    "\n",
    "    train_bovw_features = compute_bovw_representation(train_sift_features, codebook)\n",
    "    test_bovw_features = compute_bovw_representation(test_sift_features, codebook)\n",
    "\n",
    "    knn_classifier = train_knn_classifier(train_bovw_features, train_labels)\n",
    "\n",
    "    accuracy, report = evaluate_classifier(knn_classifier, test_bovw_features, train_labels)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kbD2avg8Ov5"
   },
   "source": [
    "The accuracy achieved with the provided code is relatively low, approximately 10.37%. The classification report further demonstrates that the model's precision, recall, and F1-score for each class are quite low, indicating that the model is struggling to distinguish between different categories in the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3onN3ls8Pfc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
